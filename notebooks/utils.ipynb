{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as tfs\n",
    "from scipy.signal import wiener\n",
    "import collections\n",
    "from scipy import stats\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import json  \n",
    "import os\n",
    "import seaborn as sns\n",
    "import scikit_posthocs as sp\n",
    "from IPython.display import clear_output\n",
    "import networkx as nx\n",
    "from bct.utils import BCTParamError, normalize, get_rng\n",
    "import powerlaw\n",
    "import warnings\n",
    "import matplotlib\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from scipy.cluster.hierarchy import linkage,dendrogram,fcluster\n",
    "from statsmodels.sandbox.stats.runs import runstest_1samp \n",
    "import math\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import umap.plot\n",
    "from IPython.core.display import display, HTML\n",
    "from pyrqa.time_series import TimeSeries\n",
    "from pyrqa.settings import Settings\n",
    "from pyrqa.analysis_type import Classic\n",
    "from pyrqa.neighbourhood import FixedRadius, RadiusCorridor\n",
    "from pyrqa.metric import EuclideanMetric, MaximumMetric, TaxicabMetric\n",
    "from pyrqa.computation import RQAComputation\n",
    "from pyrqa.computation import RPComputation\n",
    "from pyrqa.image_generator import ImageGenerator\n",
    "import umap\n",
    "from pyrqa.neighbourhood import Unthresholded\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_medias_sem(parameter):\n",
    "    print('{:.3f}'.format(df[df['Condition']=='Control'][parameter].mean()),'±','{:.3f}'.format(2*df[df['Condition']=='Control'][parameter].sem()))\n",
    "    print('{:.3f}'.format(df[df['Condition']=='Decorticated'][parameter].mean()),'±','{:.3f}'.format(2*df[df['Condition']=='Decorticated'][parameter].sem()))\n",
    "    print('{:.3f}'.format(df[df['Condition']=='Parkinson'][parameter].mean()),'±','{:.3f}'.format(2*df[df['Condition']=='Parkinson'][parameter].sem()))\n",
    "    print('{:.3f}'.format(df[df['Condition']=='Dyskinesia'][parameter].mean()),'±','{:.3f}'.format(2*df[df['Condition']=='Dyskinesia'][parameter].sem()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rate(raster,ci,c,bin_=4,fps=4,r=1.5):\n",
    "    N,F=raster.shape\n",
    "    indices_ci=np.where(ci==c)[0]\n",
    "    raster_cluster=raster[indices_ci,:]\n",
    "    y=np.sum(raster_cluster,axis=0)\n",
    "    rate=np.zeros(y.shape)\n",
    "    bin_b=0\n",
    "    for j in range(y.shape[0]):\n",
    "        rate[j]=np.sum(y[j-bin_b:j+1])\n",
    "        if bin_b<bin_:\n",
    "            bin_b+=1\n",
    "    fpm=fps*60\n",
    "    x=np.arange(0,F)/fpm\n",
    "    fig=plt.figure(figsize=(12,3))\n",
    "    #ax=plt.axes((0.05,0.35,0.75,0.9))\n",
    "    plt.plot(x,rate,color='black')\n",
    "    plt.xlim(np.min(x),np.max(x))\n",
    "    plt.ylim(0,np.max(rate)+1)\n",
    "    rate[np.where(rate==0)[0]]=np.nan\n",
    "    time_series = TimeSeries(rate,embedding_dimension=2,time_delay=1)\n",
    "    settings = Settings(time_series,\n",
    "                    analysis_type=Classic,\n",
    "                    neighbourhood=FixedRadius(r),    \n",
    "                    #neighbourhood=Unthresholded(),\n",
    "                    similarity_measure=EuclideanMetric,\n",
    "                    theiler_corrector=1)\n",
    "    computation = RPComputation.create(settings)\n",
    "    result = computation.run()\n",
    "    return result.recurrence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_graph(transition_matrix,cmap):\n",
    "    G = nx.DiGraph()\n",
    "    color_map=[]\n",
    "    for i in range(len(transition_matrix)):\n",
    "        G.add_node(i)\n",
    "        if type(cmap)==matplotlib.colors.LinearSegmentedColormap:\n",
    "            color_map.append(cmap(i/(len(transition_matrix)-1)))\n",
    "        else:\n",
    "            color_map.append(cmap(i))\n",
    "    for i in range(len(transition_matrix)):\n",
    "        for j in range(len(transition_matrix)):\n",
    "            if transition_matrix[i,j]>=1:\n",
    "                if type(cmap)==matplotlib.colors.LinearSegmentedColormap:\n",
    "                    G.add_edge(i,j, weight=transition_matrix[i,j],color=cmap(i/(len(transition_matrix)-1))) \n",
    "                else:\n",
    "                    G.add_edge(i,j, weight=transition_matrix[i,j],color=cmap(i))    \n",
    "    return G,color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gephi_graph(ma,cluster_index,th):\n",
    "    ma_reduced=threshold_proportional(ma, th)\n",
    "    G=nx.from_numpy_matrix(ma_reduced)\n",
    "    ensemble_attr_dict={}\n",
    "    color_attr_dict={}\n",
    "    cmap = matplotlib.cm.get_cmap('tab10')\n",
    "    for i,ci in enumerate(cluster_index):\n",
    "        ensemble_attr_dict[i]=str(ci)\n",
    "        v=list(cmap(ci)[0:3])\n",
    "        v=[vi*255 for vi in v]\n",
    "        l=len(str(v))-1\n",
    "        color_attr_dict[i]=str(v)[1:l]\n",
    "    nx.set_node_attributes(G, ensemble_attr_dict, \"ensemble\")\n",
    "    nx.set_node_attributes(G, color_attr_dict,\"color\")\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ordered_adj_matrix(ma,cluster_index):\n",
    "    ma_ordered=np.zeros(ma.shape)\n",
    "    count=0\n",
    "    new_order=[]\n",
    "    for ci in range(max(cluster_index)+1):\n",
    "        indices_ci=np.where(cluster_index==ci)[0]\n",
    "        for indice in indices_ci:\n",
    "            new_order.append(indice)\n",
    "            count+=1\n",
    "    for i in range(len(new_order)):\n",
    "        indices_i=np.where(ma[new_order[i],:]>0)[0]\n",
    "        for indice in indices_i:\n",
    "            ma_ordered[i,np.where(new_order==indice)[0]]=ma[new_order[i],indice]\n",
    "    \n",
    "    return ma_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_matrix(mapper):\n",
    "    ma=np.zeros(mapper.graph_.shape)\n",
    "    contador=0\n",
    "    for i in range(ma.shape[0]):\n",
    "        tam=mapper.graph_.indptr[i+1]-mapper.graph_.indptr[i]\n",
    "        ma[i,mapper.graph_.indices[contador:contador+tam]]=mapper.graph_.data[contador:contador+tam]\n",
    "        contador+=tam\n",
    "    return ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_matrix(colores,ci):\n",
    "    secuencia=[-1]\n",
    "    for key,values in colores.items():\n",
    "        if len(values)>=1:\n",
    "            for value in values:\n",
    "                if secuencia[-1]!=value:\n",
    "                    secuencia.append(value)\n",
    "                    break\n",
    "    del secuencia[0]\n",
    "    transition_matrix=np.zeros((max(secuencia)+1,max(secuencia)+1))\n",
    "    for i in range(len(secuencia)-1):\n",
    "        transition_matrix[secuencia[i],secuencia[i+1]]+=1\n",
    "    for i in range(max(ci)+1):\n",
    "        #transition_matrix[i,:]=(transition_matrix[i,:]/np.sum(transition_matrix[i,:]))*100\n",
    "        transition_matrix[i,:]=(transition_matrix[i,:]/np.sum(transition_matrix))*100\n",
    "    return transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(colorRGBA1, colorRGBA2):\n",
    "    red   = (colorRGBA1[0]  + colorRGBA2[0]) / 2\n",
    "    green = (colorRGBA1[1]  + colorRGBA2[1]) / 2\n",
    "    blue  = (colorRGBA1[2]  + colorRGBA2[2]) / 2\n",
    "    return (red, green, blue, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rates_ensembles(raster,ci,bin_=4,fps=4):\n",
    "    N,F=raster.shape\n",
    "    rates=np.zeros((raster.shape[1],max(ci)+1))\n",
    "    for c in range(max(ci)+1):\n",
    "        indices_ci=np.where(ci==c)[0]\n",
    "        raster_cluster=raster[indices_ci,:]\n",
    "        y=np.sum(raster_cluster,axis=0)\n",
    "        rate=np.zeros(y.shape)\n",
    "        bin_b=0\n",
    "        for j in range(y.shape[0]):\n",
    "            rate[j]=np.sum(y[j-bin_b:j+1])\n",
    "            if bin_b<bin_:\n",
    "                bin_b+=1\n",
    "        rates[:,c]=rate\n",
    "    fpm=fps*60\n",
    "    x=np.arange(0,F)/fpm\n",
    "    return rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiment_data(df,path_df):\n",
    "    try:\n",
    "        df_=pd.read_excel(path_df)\n",
    "    except:\n",
    "        df_=pd.DataFrame(columns=['Experiment','Condition','Num_Neurons','Num_Ensembles'])\n",
    "    result = pd.concat([df_,df])\n",
    "    result.to_excel(path_df, sheet_name='datos',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_recurrence_data(df,path_df,exp_name,cond):\n",
    "    df['Experiment']=exp_name\n",
    "    df['Condition']=cond\n",
    "    try:\n",
    "        df_=pd.read_excel(path_df)\n",
    "    except:\n",
    "        df_=pd.DataFrame(columns=['Ensemble','N','RR','DET','L','L_max','DIV','L_entr','LAM','TT','V_max','V_entr','W','W_max','W_div','W_entr','Experiment','Condition'])\n",
    "    result = pd.concat([df_,df])\n",
    "    result.to_excel(path_df, sheet_name='datos',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_resume_recurrence(df):\n",
    "    fig, axes = plt.subplots(1, 14,figsize=(14,4))\n",
    "    sns.boxplot(data=df['RR'], orient='v', ax=axes[0]).set(title='RR')\n",
    "    sns.boxplot(data=df['DET'], orient='v', ax=axes[1]).set(title='DET')\n",
    "    sns.boxplot(data=df['L'], orient='v', ax=axes[2]).set(title='L')\n",
    "    sns.boxplot(data=df['L_max'], orient='v', ax=axes[3]).set(title='L_max')\n",
    "    sns.boxplot(data=df['DIV'], orient='v', ax=axes[4]).set(title='DIV')\n",
    "    sns.boxplot(data=df['L_entr'], orient='v', ax=axes[5]).set(title='L_entr')\n",
    "    sns.boxplot(data=df['LAM'], orient='v', ax=axes[6]).set(title='LAM')\n",
    "    sns.boxplot(data=df['TT'], orient='v', ax=axes[7]).set(title='TT')\n",
    "    sns.boxplot(data=df['V_max'], orient='v', ax=axes[8]).set(title='V_max')\n",
    "    sns.boxplot(data=df['V_entr'], orient='v', ax=axes[9]).set(title='V_entr')\n",
    "    sns.boxplot(data=df['W'], orient='v', ax=axes[10]).set(title='W')\n",
    "    sns.boxplot(data=df['W_max'], orient='v', ax=axes[11]).set(title='W_max')\n",
    "    sns.boxplot(data=df['W_div'], orient='v', ax=axes[12]).set(title='W_div')\n",
    "    sns.boxplot(data=df['W_entr'], orient='v', ax=axes[13]).set(title='W_entr')\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tam_pico_sig(raster,window_percentage=20,n_sigma=2):\n",
    "    column = np.sum(raster,axis=0)\n",
    "    N = len(column)\n",
    "    time = np.arange(0,N)\n",
    "    k = int(len(column) * (window_percentage/100))\n",
    "    get_bands = lambda column : (np.mean(column) + n_sigma*np.std(column),np.mean(column) - n_sigma*np.std(column))\n",
    "    bands = [get_bands(column[range(0 if i - k < 0 else i-k ,i + k if i + k < N else N)]) for i in range(0,N)]\n",
    "    upper, lower = zip(*bands)\n",
    "    anomalies = (column > upper) | (column < lower)\n",
    "    \n",
    "    for j in range(N):\n",
    "        if anomalies[j]==True:\n",
    "            if column[j]<2:\n",
    "                anomalies[j]=False\n",
    "    \n",
    "    return anomalies,upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_coactivity_is_random(raster,ci,n_iter):\n",
    "    for i in range(max(ci)+1):\n",
    "        indices_ci=np.where(ci==i)[0]\n",
    "        raster_cluster=raster[indices_ci,:]\n",
    "        print('Cluster',i)\n",
    "        coactivity_is_random(raster_cluster,n_iter)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coactivity_ensambles(raster,cluster_index,n_iter,name_colormap,fps,window_percentage=20,n_sigma=2):\n",
    "    Ci=cluster_index\n",
    "    cmap = matplotlib.cm.get_cmap(name_colormap)\n",
    "    N,F=raster.shape\n",
    "    nmodules=max(Ci)+1\n",
    "    maxCo=0\n",
    "\n",
    "    for i in range(int(nmodules)):\n",
    "        tempCo=np.sum(raster[np.where(Ci==i)[0],:],axis=0)\n",
    "        if max(tempCo)>maxCo:\n",
    "            maxCo=max(tempCo)\n",
    "\n",
    "    fpm=fps*60\n",
    "    x=np.arange(0,F)/fpm\n",
    "\n",
    "    Co=np.zeros((int(nmodules),len(tempCo)))\n",
    "\n",
    "    fig=plt.figure(figsize=(12,6))\n",
    "    #ax=plt.axes((0.05,0.35,0.75,0.9))\n",
    "    plt.subplots_adjust(hspace=0.000)\n",
    "    number_of_subplots=nmodules\n",
    "    ejes=[]\n",
    "    for i in range(int(nmodules)):\n",
    "        indices_ci=np.where(Ci==i)[0]\n",
    "        raster_cluster=raster[indices_ci,:]\n",
    "        peaks,th=get_tam_pico_sig(raster_cluster,window_percentage,n_sigma)     \n",
    "        Co[i,:]=np.sum(raster[np.where(Ci==i)[0],:],axis=0)\n",
    "        ax = plt.subplot(number_of_subplots,1,number_of_subplots-i)\n",
    "        \n",
    "        if type(cmap)==matplotlib.colors.LinearSegmentedColormap:\n",
    "            ax.plot(x,Co[i,:],color=cmap(i/max(Ci)),alpha=1)\n",
    "            ax.plot(x,th,color=cmap(i/max(Ci)),alpha=0.2)\n",
    "            plt.fill_between(x, th, np.zeros(x.shape),facecolor=cmap(i/max(Ci)),alpha=0.1)\n",
    "        else:        \n",
    "            ax.plot(x,Co[i,:],color=cmap(i),alpha=1)\n",
    "            ax.plot(x,th,color=cmap(i),alpha=0.2)\n",
    "            plt.fill_between(x, th, np.zeros(x.shape),facecolor=cmap(i),alpha=0.1)\n",
    "\n",
    "        ax.set_xlim(np.min(x),np.max(x))\n",
    "        ax.set_ylim(0,maxCo+1)\n",
    "        if i==0:\n",
    "            plt.xlabel(\"Tiempo (min)\")\n",
    "            plt.ylabel(\"Coactividad\")\n",
    "        else:\n",
    "            ax.set_xticks([])\n",
    "        ejes.append(ax)\n",
    "\n",
    "    for ax in ejes:\n",
    "        pos=ax.get_position()\n",
    "        pos=pos.from_extents(0.05,pos.y0,0.8,pos.y1)\n",
    "        ax.set_position(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ensamble_raster(raster,fps,cluster_index,name_colormap,n_sigma=2,window_percentage=20,markersize=5):\n",
    "    cmap = matplotlib.cm.get_cmap(name_colormap)\n",
    "    N,F=raster.shape\n",
    "    actividad=np.zeros((N,1))\n",
    "    orden_plot=[]\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "\n",
    "    ax=plt.axes((0.05,0.35,0.75,0.6))\n",
    "    count=0\n",
    "    ensembles_in_time={}\n",
    "    for i in range(raster.shape[1]):\n",
    "        ensembles_in_time[i]=[]\n",
    "    \n",
    "    for ci in range(max(cluster_index)+1):\n",
    "        indices_ci=np.where(cluster_index==ci)[0]\n",
    "        coactividad_cluster=np.sum(raster[np.where(cluster_index==ci)[0],:],axis=0)\n",
    "        peaks,th=get_tam_pico_sig(raster[np.where(cluster_index==ci)[0],:],window_percentage,n_sigma)\n",
    "        \n",
    "        idx=np.where(peaks==True)[0]\n",
    "        for i in indices_ci:\n",
    "            orden_plot.append(i)\n",
    "            indices=np.where(raster[i,:]==1)[0]\n",
    "            \n",
    "            if type(cmap)==matplotlib.colors.LinearSegmentedColormap:\n",
    "                plt.plot(indices,raster[i,indices]*(count+1),\n",
    "                        marker='|',linestyle='None',\n",
    "                        markersize=markersize,color=cmap(ci/max(cluster_index)),alpha=0.1)\n",
    "                plt.plot(idx,raster[i,idx]*(count+1),\n",
    "                        marker='s',linestyle='None',\n",
    "                        markersize=markersize,color=cmap(ci/max(cluster_index)),alpha=1)\n",
    "            else:\n",
    "                plt.plot(indices,raster[i,indices]*(count+1),\n",
    "                        marker='|',linestyle='None',\n",
    "                        markersize=markersize,color=cmap(ci),alpha=0.1)\n",
    "                plt.plot(idx,raster[i,idx]*(count+1),\n",
    "                        marker='s',linestyle='None',\n",
    "                        markersize=markersize,color=cmap(ci),alpha=1)\n",
    "            actividad[count]=np.sum(raster[i,:])*100/F\n",
    "            count+=1\n",
    "        \n",
    "        for j,pk in enumerate(peaks):\n",
    "            if pk:\n",
    "                ensembles_in_time[j].append(ci)       \n",
    "        \n",
    "    ax.set_xlim(0,F-1)\n",
    "    ax.set_ylim(1,N)\n",
    "    plt.xticks([])\n",
    "    plt.ylabel(\"Etiqueta de Neurona\")\n",
    "\n",
    "    ax=plt.axes(((0.05,0.12,0.75,0.2)))\n",
    "    coactividad=np.sum(raster,axis=0)\n",
    "    fpm=fps*60\n",
    "    tiempo=np.arange(0,F)/fpm\n",
    "    plt.plot(tiempo,coactividad,linewidth=0.5,color='black',alpha=1)\n",
    "    ax.set_xlim(np.min(tiempo),np.max(tiempo))\n",
    "    ax.set_ylim(0,ymax=np.max(coactividad)+1)\n",
    "    plt.xlabel(\"Tiempo (min)\")\n",
    "    plt.ylabel(\"Coactividad\")\n",
    "    ymax=np.max(coactividad)+1\n",
    "    inicio=-1\n",
    "    final=-1\n",
    "    bin_=markersize+2\n",
    "    for ci in range(max(cluster_index)+1):\n",
    "        for key,value in ensembles_in_time.items():\n",
    "            encontre=False\n",
    "            if len(value)>0:\n",
    "                for ensemble in value:\n",
    "                    if ensemble==ci:\n",
    "                        encontre=True\n",
    "                        if inicio<0:\n",
    "                            inicio=key\n",
    "                            final=key\n",
    "                        else:\n",
    "                            final=key\n",
    "                        break\n",
    "                if encontre==False:\n",
    "                    if final>0:\n",
    "                        if inicio-bin_<0:\n",
    "                            if final+bin_>F:\n",
    "                                x=tiempo[0:F]\n",
    "                            else:\n",
    "                                x=tiempo[0:final+bin_]\n",
    "                        elif final+bin_>F:\n",
    "                            x=tiempo[inicio-bin_:F]\n",
    "                        else:\n",
    "                            x=tiempo[inicio-bin_:final+bin_]\n",
    "                        if type(cmap)==matplotlib.colors.LinearSegmentedColormap:\n",
    "                            plt.fill_between(x, np.ones(x.shape)*ymax, np.zeros(x.shape),facecolor=cmap(ci/max(cluster_index)),alpha=0.5)\n",
    "                        else:\n",
    "                            plt.fill_between(x, np.ones(x.shape)*ymax, np.zeros(x.shape),facecolor=cmap(ci),alpha=0.5)\n",
    "                        inicio=-1\n",
    "                        final=-1\n",
    "            if encontre==False:\n",
    "                if final>0:\n",
    "                    if inicio-bin_<0:\n",
    "                        if final+bin_>F:\n",
    "                            x=tiempo[0:F]\n",
    "                        else:\n",
    "                            x=tiempo[0:final+bin_]\n",
    "                    elif final+bin_>F:\n",
    "                        x=tiempo[inicio-bin_:F]\n",
    "                    else:\n",
    "                        x=tiempo[inicio-bin_:final+bin_]\n",
    "                    if type(cmap)==matplotlib.colors.LinearSegmentedColormap:\n",
    "                        plt.fill_between(x, np.ones(x.shape)*ymax, np.zeros(x.shape),facecolor=cmap(ci/max(cluster_index)),alpha=0.5)\n",
    "                    else:\n",
    "                        plt.fill_between(x, np.ones(x.shape)*ymax, np.zeros(x.shape),facecolor=cmap(ci),alpha=0.5)\n",
    "                    inicio=-1\n",
    "                    final=-1\n",
    "                    \n",
    "                    \n",
    "    \n",
    "    ax=plt.axes((0.85,0.35,0.1,0.6))\n",
    "    plt.plot(actividad,np.arange(1,N+1),color='black',linewidth=1)\n",
    "    ax.set_xlim(0,max(actividad)+1)\n",
    "    ax.set_ylim(1,N)\n",
    "    plt.xlabel(\"Cuadros activos\")\n",
    "    plt.yticks([])\n",
    "    return orden_plot,ensembles_in_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2D_projection_vectors(raster,ci,n_cmap,window_percentage,n_sigma,min_dist,random_state,metric):\n",
    "    cmap = matplotlib.cm.get_cmap(n_cmap)  \n",
    "    colores={}\n",
    "    for i in range(raster.shape[1]):\n",
    "        colores[i]=[]\n",
    "    for i in range(max(ci)+1):\n",
    "        indices_ci=np.where(ci==i)[0]\n",
    "        raster_cluster=raster[indices_ci,:]    \n",
    "        peaks,th=get_tam_pico_sig(raster_cluster,window_percentage,n_sigma)\n",
    "        for j,pk in enumerate(peaks):\n",
    "            if pk:\n",
    "                colores[j].append(i)\n",
    "                \n",
    "    raster_ensemble=np.empty((raster.shape[0],0), int)\n",
    "    color_to_plot=[]\n",
    "    count=0\n",
    "    for i in range(raster.shape[1]):\n",
    "        list_=colores[i]\n",
    "        if len(list_)>0:\n",
    "            for item in list_:\n",
    "                raster_ensemble=np.append(raster_ensemble, np.expand_dims(raster[:,i], axis=1), axis=1)\n",
    "                raster_ensemble[np.where(ci!=item)[0],count]=0\n",
    "                color_to_plot.append(item)\n",
    "                count+=1\n",
    "\n",
    "    mapper = umap.UMAP(min_dist=min_dist,n_components=2,random_state=random_state,metric=metric).fit(raster_ensemble.T)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    for i in range(raster_ensemble.shape[1]):\n",
    "        ax.scatter(mapper.embedding_[i, 0], mapper.embedding_[i, 1], s=25, color=cmap(color_to_plot[i]),alpha=0.6)\n",
    "    \n",
    "#     mapper = umap.UMAP(min_dist=min_dist,n_components=2,random_state=random_state,metric=metric).fit(raster.T)\n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_subplot(111)\n",
    "#     sin_actividad=np.where(np.sum(raster,axis=0)<2)[0]\n",
    "#     for i in range(raster.shape[1]):\n",
    "#         if i not in sin_actividad:\n",
    "#             if len(colores[i])>0:\n",
    "#                 ax.scatter(mapper.embedding_[i, 0], mapper.embedding_[i, 1], s=25, color=cmap(colores[i][0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3D_projection_vectors(raster,ci,n_cmap,window_percentage,n_sigma,min_dist,random_state,metric):\n",
    "    #%matplotlib notebook\n",
    "    cmap = matplotlib.cm.get_cmap(n_cmap)  \n",
    "    colores={}\n",
    "    for i in range(raster.shape[1]):\n",
    "        colores[i]=[]\n",
    "    for i in range(max(ci)+1):\n",
    "        indices_ci=np.where(ci==i)[0]\n",
    "        raster_cluster=raster[indices_ci,:]    \n",
    "        peaks,th=get_tam_pico_sig(raster_cluster,window_percentage,n_sigma)\n",
    "        for j,pk in enumerate(peaks):\n",
    "            if pk:\n",
    "                colores[j].append(i)\n",
    "    raster_ensemble=np.empty((raster.shape[0],0), int)\n",
    "    color_to_plot=[]\n",
    "    count=0\n",
    "    for i in range(raster.shape[1]):\n",
    "        list_=colores[i]\n",
    "        if len(list_)>0:\n",
    "            for item in list_:\n",
    "                raster_ensemble=np.append(raster_ensemble, np.expand_dims(raster[:,i], axis=1), axis=1)\n",
    "                raster_ensemble[np.where(ci!=item)[0],count]=0\n",
    "                color_to_plot.append(item)\n",
    "                count+=1            \n",
    "    \n",
    "    mapper = umap.UMAP(min_dist=min_dist,n_components=3,random_state=random_state,metric=metric).fit(raster_ensemble.T)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for i in range(raster_ensemble.shape[1]):\n",
    "        if type(cmap)==matplotlib.colors.LinearSegmentedColormap:\n",
    "            ax.scatter(mapper.embedding_[i, 0], mapper.embedding_[i, 1],mapper.embedding_[i, 2],\n",
    "                       s=15, color=cmap(color_to_plot[i]/max(color_to_plot)))\n",
    "        else:\n",
    "            ax.scatter(mapper.embedding_[i, 0], mapper.embedding_[i, 1],mapper.embedding_[i, 2],\n",
    "                       s=15, color=cmap(color_to_plot[i]))\n",
    "    \n",
    "    return mapper,color_to_plot,colores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recurrence_analysis(raster,ci,r=1.5,bin_=4):\n",
    "    df=pd.DataFrame(columns=['Ensemble','N','RR','DET','L','L_max','DIV','L_entr','LAM','TT','V_max','V_entr','W','W_max','W_div','W_entr'])\n",
    "    for i in range(max(ci)+1):\n",
    "        indices_ci=np.where(ci==i)[0]\n",
    "        raster_cluster=raster[indices_ci,:]\n",
    "        y=np.sum(raster_cluster,axis=0)\n",
    "        rate=np.zeros(y.shape)\n",
    "        bin_b=0\n",
    "        for j in range(y.shape[0]):\n",
    "            rate[j]=np.sum(y[j-bin_b:j+1])\n",
    "            if bin_b<bin_:\n",
    "                bin_b+=1\n",
    "        rate[np.where(rate==0)[0]]=np.nan\n",
    "        time_series = TimeSeries(rate,embedding_dimension=2,time_delay=1)\n",
    "\n",
    "        settings = Settings(time_series,\n",
    "                            analysis_type=Classic,\n",
    "                            neighbourhood=FixedRadius(r),\n",
    "                            similarity_measure=EuclideanMetric,\n",
    "                            theiler_corrector=1)\n",
    "        computation = RQAComputation.create(settings,\n",
    "                                        verbose=True)\n",
    "\n",
    "        result = computation.run()\n",
    "        result.min_diagonal_line_length = 2\n",
    "        result.min_vertical_line_length = 2\n",
    "        result.min_white_vertical_line_length = 2\n",
    "        fila={'Ensemble':i,'N':len(indices_ci),\n",
    "              'RR':result.recurrence_rate,'DET':result.determinism,\n",
    "              'L':result.average_diagonal_line,'L_max':result.longest_diagonal_line,'DIV':result.divergence,\n",
    "              'L_entr':result.entropy_diagonal_lines,'LAM':result.laminarity,\n",
    "              'TT':result.laminarity,'V_max':result.longest_vertical_line,\n",
    "              'V_entr':result.entropy_vertical_lines,'W':result.average_white_vertical_line,\n",
    "              'W_max':result.longest_white_vertical_line,'W_div':result.longest_white_vertical_line_inverse,\n",
    "              'W_entr':result.entropy_white_vertical_lines}\n",
    "        df=df.append(fila, ignore_index=True)\n",
    "        clear_output()\n",
    "\n",
    "    # v_max=0\n",
    "    # for i in range(max(ci)+1):\n",
    "    #     indices_ci=np.where(ci==i)[0]\n",
    "    #     raster_cluster=raster[indices_ci,:]\n",
    "    #     y=np.sum(raster_cluster,axis=0)\n",
    "    #     #y[np.where(y<tam_pico_sig[i])]=0\n",
    "    #     rate=np.zeros(y.shape)\n",
    "    #     bin_b=0\n",
    "    #     for j in range(y.shape[0]):\n",
    "    #         rate[j]=np.sum(y[j-bin_b:j+1])\n",
    "    #         if bin_b<bin_:\n",
    "    #             bin_b+=1\n",
    "    #     time_series = TimeSeries(rate,embedding_dimension=2,time_delay=1)\n",
    "    #     settings = Settings(time_series,\n",
    "    #                     analysis_type=Classic,\n",
    "    #                     neighbourhood=FixedRadius(1.5),\n",
    "    #                     #neighbourhood=Unthresholded(),\n",
    "    #                     similarity_measure=EuclideanMetric,\n",
    "    #                     theiler_corrector=1)\n",
    "    #     computation = RPComputation.create(settings)\n",
    "    #     result = computation.run()\n",
    "    #     if np.max(result.recurrence_matrix)>v_max:\n",
    "    #         v_max=np.max(result.recurrence_matrix)\n",
    "    # v_max=math.ceil(v_max)\n",
    "    v_max=1\n",
    "    for i in range(max(ci)+1):\n",
    "        indices_ci=np.where(ci==i)[0]\n",
    "        raster_cluster=raster[indices_ci,:]\n",
    "        y=np.sum(raster_cluster,axis=0)\n",
    "        rate=np.zeros(y.shape)\n",
    "        bin_b=0\n",
    "        for j in range(y.shape[0]):\n",
    "            rate[j]=np.sum(y[j-bin_b:j+1])\n",
    "            if bin_b<bin_:\n",
    "                bin_b+=1\n",
    "        rate[np.where(rate==0)[0]]=np.nan\n",
    "        time_series = TimeSeries(rate,embedding_dimension=2,time_delay=1)\n",
    "        settings = Settings(time_series,\n",
    "                        analysis_type=Classic,\n",
    "                        neighbourhood=FixedRadius(r),    \n",
    "                        #neighbourhood=Unthresholded(),\n",
    "                        similarity_measure=EuclideanMetric,\n",
    "                        theiler_corrector=1)\n",
    "        computation = RPComputation.create(settings)\n",
    "        result = computation.run()\n",
    "        plt.matshow(result.recurrence_matrix,cmap='Blues',vmin=0, vmax=v_max)\n",
    "        plt.colorbar()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coactivity_is_random(raster,n_iter):\n",
    "    coactividad=np.sum(raster,axis=0)\n",
    "    rt,p=runstest_1samp(coactividad,cutoff='mean',correction=False)\n",
    "    print('rt =',rt)\n",
    "    print('p =',p)\n",
    "    #type 1 error\n",
    "    Im=0\n",
    "    for i in range(n_iter):\n",
    "        raster_s=raster_subrogado(raster,1)\n",
    "        coactividad_s=np.sum(raster_s,axis=0)\n",
    "        rt_s,p_s=runstest_1samp(coactividad_s,cutoff='median',correction=False)\n",
    "        if p_s<=0.05:\n",
    "            Im+=1\n",
    "    alphahat=Im/n_iter\n",
    "    print('alphahat',alphahat)\n",
    "    #type 2 error\n",
    "    Im=0\n",
    "    for i in range(n_iter):\n",
    "        raster_s=raster_subrogado(raster,2)\n",
    "        coactividad_s=np.sum(raster_s,axis=0)\n",
    "        rt_s,p_s=runstest_1samp(coactividad_s,cutoff='median',correction=False)\n",
    "        if p_s>0.05:\n",
    "            Im+=1\n",
    "    betahat=Im/n_iter\n",
    "    print('betahat',betahat)\n",
    "    return rt,p,alphahat,betahat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram_isi(tiempo_spikes,n_bins=50):\n",
    "    isi=np.diff(tiempo_spikes)\n",
    "    plt.hist(isi, bins=n_bins, density=True, color='lightblue', edgecolor='black')\n",
    "    plt.title('Histograma ISI')\n",
    "    plt.xlabel('Intervalo Interespiga [s]')\n",
    "    plt.ylabel('Densidad de Probabilidad')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_coactividad_significativa_clusters(raster_real,ci,n_iter,p): \n",
    "    tam_pico_sig=[]\n",
    "    for i in range(max(ci)+1):\n",
    "        indices_ci=np.where(ci==i)[0]\n",
    "        raster_cluster=raster[indices_ci,:]\n",
    "        hist_real_cum,lista_hist_cum_subrogada=coctivity_test(raster_cluster, n_iter)\n",
    "        for j in range(len(lista_hist_cum_subrogada)):\n",
    "            for k in range(len(hist_real_cum)-len(lista_hist_cum_subrogada[j])):\n",
    "                lista_hist_cum_subrogada[j].append(0)\n",
    "        for n in range(2,len(hist_real_cum)):\n",
    "            vc=np.percentile([lista[n] for lista in lista_hist_cum_subrogada],100-p*100)\n",
    "            if hist_real_cum[n]>vc:\n",
    "                tam_pico_sig.append(n)\n",
    "                break\n",
    "    return tam_pico_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coctivity_test(raster_real, n_iter, opt):\n",
    "    coactividad_real=np.sum(raster_real,axis=0)\n",
    "    frecuencia_coactividad=collections.Counter(coactividad_real)\n",
    "    hist_real_cum=[]\n",
    "    for i in range(int(np.max(list(frecuencia_coactividad.keys()))+1)):\n",
    "        suma=0\n",
    "        for j in range(i,int(np.max(list(frecuencia_coactividad.keys()))+1)):\n",
    "            suma+=frecuencia_coactividad[j]\n",
    "        hist_real_cum.append(suma)\n",
    "\n",
    "    lista_hist_subrogada=[]\n",
    "    lista_hist_cum_subrogada=[]\n",
    "    for i in range(n_iter):\n",
    "        raster_sub=raster_subrogado(raster_real,opt)\n",
    "        coactividad_subrogada=np.sum(raster_sub,axis=0)\n",
    "        frecuencia_coactividad_subrogada=collections.Counter(coactividad_subrogada.astype(int))\n",
    "        lista_hist_subrogada.append(frecuencia_coactividad_subrogada)\n",
    "        hist_sub_cum=[]\n",
    "        for i in range(int(np.max(list(frecuencia_coactividad_subrogada.keys()))+1)):\n",
    "            suma=0\n",
    "            for j in range(i,int(np.max(list(frecuencia_coactividad_subrogada.keys()))+1)):\n",
    "                suma+=frecuencia_coactividad_subrogada[j]\n",
    "            hist_sub_cum.append(suma)\n",
    "        lista_hist_cum_subrogada.append(hist_sub_cum)\n",
    "    return hist_real_cum,lista_hist_cum_subrogada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coactividad_clusters_h(raster,Ci,name_colormap,fps,tam_pico_sig=None):\n",
    "    cmap = matplotlib.cm.get_cmap(name_colormap)\n",
    "    N,F=raster.shape\n",
    "    nmodules=max(Ci)+1\n",
    "    maxCo=0\n",
    "\n",
    "    for i in range(nmodules):\n",
    "        tempCo=np.sum(raster[np.where(Ci==i)[0],:],axis=0)\n",
    "        if max(tempCo)>maxCo:\n",
    "            maxCo=max(tempCo)\n",
    "\n",
    "    fpm=fps*60\n",
    "    x=np.arange(0,F)/fpm\n",
    "\n",
    "    Co=np.zeros((nmodules,len(tempCo)))\n",
    "\n",
    "    fig=plt.figure(figsize=(12,6))\n",
    "    #ax=plt.axes((0.05,0.35,0.75,0.9))\n",
    "    plt.subplots_adjust(hspace=0.000)\n",
    "    number_of_subplots=nmodules\n",
    "    ejes=[]\n",
    "    for i in range(nmodules):\n",
    "        Co[i,:]=np.sum(raster[np.where(Ci==i)[0],:],axis=0)\n",
    "        ax = plt.subplot(number_of_subplots,1,number_of_subplots-i)\n",
    "        ax.plot(x,Co[i,:],color=cmap(i))\n",
    "        if len(tam_pico_sig)>0:\n",
    "            ax.plot([min(x),max(x)],[tam_pico_sig[i]-0.2,tam_pico_sig[i]-0.2],linestyle='--',color='black',linewidth=1)\n",
    "        ax.set_xlim(np.min(x),np.max(x))\n",
    "        ax.set_ylim(0,maxCo+1)\n",
    "        if i==0:\n",
    "            plt.xlabel(\"Tiempo (min)\")\n",
    "            plt.ylabel(\"Coactividad\")\n",
    "        else:\n",
    "            ax.set_xticks([])\n",
    "        ejes.append(ax)\n",
    "\n",
    "    for ax in ejes:\n",
    "        pos=ax.get_position()\n",
    "        pos=pos.from_extents(0.05,pos.y0,0.8,pos.y1)\n",
    "        ax.set_position(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coactividad_significativa_clusters_h(raster_real,ci,n_iter,p,graficar=False): \n",
    "    tam_pico_sig=[]\n",
    "    for i in range(max(ci)+1):\n",
    "        indices_ci=np.where(ci==i)[0]\n",
    "        raster_cluster=raster[indices_ci,:]\n",
    "        tam_picos,ps,_=test_coactividad_significativa(raster_cluster,n_iter,p,graficar)\n",
    "        prueba=ps[2:]\n",
    "        indice=np.nan\n",
    "        for idx,valor in enumerate(prueba):\n",
    "            if valor<p:\n",
    "                indice=idx\n",
    "                break\n",
    "        tam_pico_sig.append(indice+2)\n",
    "    return tam_pico_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_error_tipo_1(raster_real,n_iter,n_ensayos,n_neu_pico,alpha):\n",
    "    sumas_hipotesis=[]\n",
    "    for ni in range(10000):\n",
    "        raster_hipotesis=raster_subrogado(raster_real,1)\n",
    "        coactividad_hipotesis=np.sum(raster_hipotesis,axis=0)\n",
    "        frecuencia_coactividad=collections.Counter(coactividad_hipotesis)\n",
    "        suma_hipotesis=0\n",
    "        for i in range(n_neu_pico,len(frecuencia_coactividad)):\n",
    "            suma_hipotesis+=frecuencia_coactividad[i]\n",
    "        sumas_hipotesis.append(suma_hipotesis)\n",
    "    valor_critico=np.quantile(sumas_hipotesis, 1-alpha)\n",
    "\n",
    "    p_ensayos=[]\n",
    "    for ne in range(n_ensayos):\n",
    "        frecuencia_subrogada=[]\n",
    "        for ni in range(n_iter):\n",
    "            raster_sub=raster_subrogado(raster_hipotesis,1)\n",
    "            coactividad_subrogada=np.sum(raster_sub,axis=0)\n",
    "            frecuencia_coactividad_subrogada=collections.Counter(coactividad_subrogada.astype(int))\n",
    "            suma_subr=0\n",
    "            for i in range(n_neu_pico,len(frecuencia_coactividad_subrogada)):\n",
    "                suma_subr+=frecuencia_coactividad_subrogada[i]\n",
    "            frecuencia_subrogada.append(suma_subr)\n",
    "        p_ensayos.append(len(np.where(valor_critico<np.array(frecuencia_subrogada))[0])/n_iter)\n",
    "    plt.boxplot(p_ensayos)\n",
    "    plt.title('Alpha error tipo 1')\n",
    "    plt.show()\n",
    "    \n",
    "    return p_ensayos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_error_tipo_2(raster_real,n_iter,n_ensayos,n_neu_pico,alpha):\n",
    "    sumas_hipotesis=[]\n",
    "    for ni in range(10000):\n",
    "        raster_hipotesis=raster_subrogado(raster_real,2)\n",
    "        coactividad_hipotesis=np.sum(raster_hipotesis,axis=0)\n",
    "        frecuencia_coactividad=collections.Counter(coactividad_hipotesis)\n",
    "        suma_hipotesis=0\n",
    "        for i in range(n_neu_pico,len(frecuencia_coactividad)):\n",
    "            suma_hipotesis+=frecuencia_coactividad[i]\n",
    "        sumas_hipotesis.append(suma_hipotesis)\n",
    "    valor_critico=np.quantile(sumas_hipotesis, 1-alpha)\n",
    "\n",
    "    p_ensayos=[]\n",
    "    for ne in range(n_ensayos):\n",
    "        frecuencia_subrogada=[]\n",
    "        for ni in range(n_iter):\n",
    "            raster_sub=raster_subrogado(raster_hipotesis,1)\n",
    "            coactividad_subrogada=np.sum(raster_sub,axis=0)\n",
    "            frecuencia_coactividad_subrogada=collections.Counter(coactividad_subrogada.astype(int))\n",
    "            suma_subr=0\n",
    "            for i in range(n_neu_pico,len(frecuencia_coactividad_subrogada)):\n",
    "                suma_subr+=frecuencia_coactividad_subrogada[i]\n",
    "            frecuencia_subrogada.append(suma_subr)\n",
    "        p_ensayos.append(len(np.where(valor_critico<np.array(frecuencia_subrogada))[0])/n_iter)\n",
    "    plt.boxplot(p_ensayos)\n",
    "    plt.title('Beta error tipo 2')\n",
    "    plt.show()\n",
    "    return p_ensayos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters_modularidad(grafo_ponderado,n_iter):\n",
    "    N=len(grafo_ponderado)\n",
    "    mat_mismo_grupo=np.zeros(grafo_ponderado.shape)\n",
    "    for i in range(n_iter):\n",
    "        cluster_index,_=community_louvain(grafo_ponderado,seed=42)\n",
    "        for neu in range(N):\n",
    "            module = cluster_index[neu]\n",
    "            index = np.where(cluster_index==module)[0]\n",
    "            mat_mismo_grupo[neu,index]+=1\n",
    "    for i in range(N):\n",
    "        mat_mismo_grupo[i,i]=0\n",
    "    cluster_index_h,_=community_louvain(mat_mismo_grupo,seed=42)    \n",
    "    cluster_index_h=cluster_index_h-1\n",
    "    print(\"Number of Ensembles: \",str(max(cluster_index_h)+1))\n",
    "    return cluster_index_h,mat_mismo_grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mundo_pequeño(G,n_iter):\n",
    "    n=len(G.nodes)\n",
    "    k=len(G.edges)\n",
    "    buscar=True\n",
    "    knn=2\n",
    "    while buscar:\n",
    "      GA=nx.watts_strogatz_graph(n,knn,p=0)\n",
    "      if len(GA.edges)>k:\n",
    "        buscar=False\n",
    "      else:\n",
    "        knn+=2\n",
    "    count=0\n",
    "    L_L=[]\n",
    "    L_R=[]\n",
    "    C_L=[]\n",
    "    C_R=[]\n",
    "    while count < n_iter:\n",
    "      GL = GA.copy()\n",
    "      while len(GL.edges)>k:\n",
    "        degrees_iter = np.array([GL.degree(n) for n in GL.nodes()])\n",
    "        max_degree=max(degrees_iter)\n",
    "        n_del=np.random.choice(np.where(degrees_iter==max_degree)[0])\n",
    "        lista_enlaces=list(GL.edges)\n",
    "        lista_quitar=[]\n",
    "        for i in range(len(lista_enlaces)):\n",
    "          if lista_enlaces[i][0]==n_del or lista_enlaces[i][1]==n_del:\n",
    "            lista_quitar.append(i)\n",
    "        elem_del=[]\n",
    "        for i in range(len(lista_quitar)):\n",
    "          if degrees_iter[lista_enlaces[lista_quitar[i]][0]]<max_degree or degrees_iter[lista_enlaces[lista_quitar[i]][1]]<max_degree:\n",
    "            elem_del.append(i)\n",
    "        delete_multiple_element(lista_quitar, elem_del)\n",
    "        if len(lista_quitar)==0:\n",
    "          continue\n",
    "        edge_del=np.random.choice(lista_quitar)\n",
    "        GL.remove_edge(lista_enlaces[edge_del][0],lista_enlaces[edge_del][1])\n",
    "      GR = GL.copy()\n",
    "      lista_enlaces=list(GR.edges)\n",
    "      lista_nodos=list(GR.nodes)\n",
    "      for enlace in lista_enlaces:\n",
    "        lista_w=lista_nodos.copy()\n",
    "        u=enlace[0]\n",
    "        v=enlace[1]\n",
    "        not_w=[u]\n",
    "        for node in GR.edges(u):\n",
    "          not_w.append(node[1])\n",
    "        delete_multiple_element(lista_w, not_w)\n",
    "        w=np.random.choice(lista_w)\n",
    "        GR.remove_edge(u,v)\n",
    "        GR.add_edge(u,w)\n",
    "      if not nx.is_connected(GR):\n",
    "        continue\n",
    "      count+=1\n",
    "      C_R.append(nx.average_clustering(GR))\n",
    "      L_R.append(nx.average_shortest_path_length(GR))\n",
    "      C_L.append(nx.average_clustering(GL))\n",
    "      L_L.append(nx.average_shortest_path_length(GL))\n",
    "    \n",
    "    C=nx.average_clustering(G)\n",
    "    L=nx.average_shortest_path_length(G)\n",
    "    print(\"C = \",C)\n",
    "    print(\"L = \",L)\n",
    "    \n",
    "    C_R_mean = np.mean(C_R)\n",
    "    L_R_mean = np.mean(L_R)\n",
    "    C_L_mean = np.mean(C_L)\n",
    "    L_L_mean = np.mean(L_L)\n",
    "    \n",
    "    smallworldness_all=[]\n",
    "    for i in range(n_iter):\n",
    "      smallworldness_all.append((L/L_R[i])-(C/C_L[i]))\n",
    "    smallworldness_mean=np.mean(smallworldness_all)\n",
    "    print(\"smallworldness = \",smallworldness_mean)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.hist(smallworldness_all,density=True)\n",
    "    plt.title('Smallworldness')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.boxplot([C_L,C,C_R])\n",
    "    plt.ylabel(\"Coeficiente de Agrupamiento\")\n",
    "    plt.xticks([1, 2, 3], ['Regular', 'Real', 'Aleatoria'])\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.boxplot([L_L,L,L_R])\n",
    "    plt.ylabel(\"Shortest path length\")\n",
    "    plt.xticks([1, 2, 3], ['Regular', 'Real', 'Aleatoria'])\n",
    "    \n",
    "    salida={'L':L,'C':C,'C_Laticce':C_L_mean,'L_Laticce':L_L_mean,'C_Random':C_R_mean,'L_Random':L_R_mean,\n",
    "           'Smallworldness':smallworldness_mean}\n",
    "    \n",
    "    return salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribucion_grados(G):\n",
    "    degrees = np.array([G.degree(n) for n in G.nodes()])\n",
    "    hist, bin_edge=np.histogram(degrees, bins=range(min(degrees),max(degrees)+2),density=True)\n",
    "    plt.bar(bin_edge[:-1],hist,width=1)\n",
    "    plt.xlim([0,max(degrees)+1])\n",
    "    plt.gca().set_xticks(range(1,max(degrees)+1))\n",
    "    plt.xlabel(\"Grado [k]\")\n",
    "    plt.ylabel(\"P(k)\")\n",
    "    plt.title(\"Distribución de Grados\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_similaridad_clusters(raster,cluster_index_h,cluster_index_v,umbral):\n",
    "    N,F=raster.shape\n",
    "    coactividad=np.sum(raster,axis=0)\n",
    "    indices_coactividad_sig=np.where(coactividad>=umbral)[0]\n",
    "    vectores_columna=raster[:,indices_coactividad_sig]\n",
    "    informacion={}\n",
    "    for ci in range(max(cluster_index_v)+1):\n",
    "        informacion[\"cluster_\"+str(ci)]={}\n",
    "        ind_ci=np.where(cluster_index_v==ci)[0]\n",
    "        for i in ind_ci:\n",
    "            neu_act=np.where(vectores_columna[:,i]==1)[0]\n",
    "            for neu in neu_act:\n",
    "                if neu not in informacion[\"cluster_\"+str(ci)]:\n",
    "                    informacion[\"cluster_\"+str(ci)][neu] = 1\n",
    "                else:\n",
    "                    informacion[\"cluster_\"+str(ci)][neu] += 1    \n",
    "    cluster_pref_neu=np.zeros((N,))\n",
    "    cluster_pref_neu[:] = np.nan\n",
    "    tam_pref_neu=np.zeros((N,))\n",
    "    for n in range(N):\n",
    "        count=0\n",
    "        for key in informacion:\n",
    "            if n in informacion[key]:\n",
    "                if informacion[key][n]>tam_pref_neu[n]:\n",
    "                    cluster_pref_neu[n]=count\n",
    "                    tam_pref_neu[n]=informacion[key][n]\n",
    "            count+=1\n",
    "    orden_aparicion=[]\n",
    "    for i in range(len(cluster_index_v)):\n",
    "        if i==0:\n",
    "            orden_aparicion.append(cluster_index_v[i])\n",
    "        if cluster_index_v[i] not in orden_aparicion:\n",
    "            orden_aparicion.append(cluster_index_v[i])\n",
    "    orden_indices=[]\n",
    "    for i in orden_aparicion:\n",
    "        neu_ind_reorder=np.where(cluster_pref_neu==i)[0]\n",
    "        orden_indices.append([neu_ind_reorder])\n",
    "    neu_ind_reorder=np.argwhere(np.isnan(cluster_pref_neu))\n",
    "    orden_indices.append([np.array([i[0] for i in neu_ind_reorder])])\n",
    "    \n",
    "    neu_clus_h={}\n",
    "    for ci in range(max(cluster_index_h)+1):\n",
    "        neu_clus_h[\"cluster_\"+str(ci)]=[]\n",
    "    for n in range(len(cluster_index_h)):\n",
    "        neu_clus_h['cluster_'+str(cluster_index_h[n])].append(n)\n",
    "        \n",
    "    neu_clus_v={}\n",
    "    for ci in range(int(max(cluster_pref_neu)+1)):\n",
    "        neu_clus_v[\"cluster_\"+str(ci)]=[]    \n",
    "    for key,valor in informacion.items():\n",
    "        for neu in valor:\n",
    "            neu_clus_v[key].append(neu)\n",
    "            \n",
    "    mat_sobrelape_1=np.zeros((len(neu_clus_h),len(neu_clus_h)))    \n",
    "    mat_sobrelape_2=np.zeros((len(neu_clus_h),len(neu_clus_h)))\n",
    "    i=0\n",
    "    for key_1,valor_1 in neu_clus_h.items():\n",
    "        j=0\n",
    "        for key_2,valor_2 in neu_clus_v.items():\n",
    "            mat_sobrelape_1[i,j]=len(np.intersect1d(valor_1,valor_2))/len(valor_1)\n",
    "            mat_sobrelape_2[j,i]=len(np.intersect1d(valor_1,valor_2))/len(valor_2)\n",
    "            j+=1\n",
    "        i+=1\n",
    "    \n",
    "    max_sim_1=[]\n",
    "    for i in range(len(mat_sobrelape_1)):\n",
    "        max_sim_1.append(max(mat_sobrelape_1[i,:])*100)\n",
    "    max_sim_2=[]\n",
    "    for i in range(len(mat_sobrelape_2)):\n",
    "        max_sim_2.append(max(mat_sobrelape_2[i,:])*100)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2 , figsize=(12,8))\n",
    "    \n",
    "    im1 = ax1.matshow(mat_sobrelape_1,cmap='jet',vmin = 0, vmax = 1)\n",
    "    fig.colorbar(im1, ax=ax1)\n",
    "    ax1.set_title(\"Horizontal\")\n",
    "    ax1.xaxis.set_ticks_position('bottom')\n",
    "    ax1.set_ylabel('Cluster Horizontal')\n",
    "    ax1.set_xlabel('Cluster Vertical')\n",
    "    \n",
    "    im2 = ax2.matshow(mat_sobrelape_2,cmap='jet',vmin = 0, vmax = 1)\n",
    "    fig.colorbar(im2, ax=ax2)\n",
    "    ax2.set_title(\"Vertical\")\n",
    "    ax2.xaxis.set_ticks_position('bottom')\n",
    "    ax2.set_ylabel('Cluster Vertical')\n",
    "    ax2.set_xlabel('Cluster Horizontal')\n",
    "    \n",
    "    plt.figure(figsize=(10,5))  \n",
    "    plt.boxplot([max_sim_1,max_sim_2])\n",
    "    plt.xticks([1, 2], ['Horizontal', 'Vertical'])\n",
    "    plt.ylabel(\"% inclusión\")\n",
    "    plt.ylim(-10,110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_color_clusters(cluster_index,name_colormap):\n",
    "    gradient = np.linspace(0, 10, 10)\n",
    "    gradient = np.vstack((gradient, gradient))\n",
    "    plt.figure(figsize=(5,1))\n",
    "    plt.imshow(gradient, aspect='auto', cmap=plt.get_cmap(name_colormap))\n",
    "    plt.xlim(-0.5,max(cluster_index)+0.5)\n",
    "    plt.xlabel(\"Número del Cluster\")\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return array[idx-1]\n",
    "    else:\n",
    "        return array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_raster_v(raster,fps,cluster_index,name_colormap,umbral,smoothing=False,markersize=5):\n",
    "    N,F=raster.shape\n",
    "    coactividad=np.sum(raster,axis=0)\n",
    "    indices_coactividad_sig=np.where(coactividad>=umbral)[0]\n",
    "    vectores_columna=raster[:,indices_coactividad_sig]\n",
    "    informacion={}\n",
    "    for ci in range(max(cluster_index)+1):\n",
    "        informacion[\"cluster_\"+str(ci)]={}\n",
    "        ind_ci=np.where(cluster_index==ci)[0]\n",
    "        for i in ind_ci:\n",
    "            neu_act=np.where(vectores_columna[:,i]==1)[0]\n",
    "            for neu in neu_act:\n",
    "                if neu not in informacion[\"cluster_\"+str(ci)]:\n",
    "                    informacion[\"cluster_\"+str(ci)][neu] = 1\n",
    "                else:\n",
    "                    informacion[\"cluster_\"+str(ci)][neu] += 1    \n",
    "    cluster_pref_neu=np.zeros((N,))\n",
    "    cluster_pref_neu[:] = np.nan\n",
    "    tam_pref_neu=np.zeros((N,))\n",
    "    for n in range(N):\n",
    "        count=0\n",
    "        for key in informacion:\n",
    "            if n in informacion[key]:\n",
    "                if informacion[key][n]>tam_pref_neu[n]:\n",
    "                    cluster_pref_neu[n]=count\n",
    "                    tam_pref_neu[n]=informacion[key][n]\n",
    "            count+=1\n",
    "    orden_aparicion=[]\n",
    "    for i in range(len(cluster_index)):\n",
    "        if i==0:\n",
    "            orden_aparicion.append(cluster_index[i])\n",
    "        if cluster_index[i] not in orden_aparicion:\n",
    "            orden_aparicion.append(cluster_index[i])\n",
    "    orden_indices=[]\n",
    "    for i in orden_aparicion:\n",
    "        neu_ind_reorder=np.where(cluster_pref_neu==i)[0]\n",
    "        orden_indices.append([neu_ind_reorder])\n",
    "    neu_ind_reorder=np.argwhere(np.isnan(cluster_pref_neu))\n",
    "    orden_indices.append([np.array([i[0] for i in neu_ind_reorder])])\n",
    "    raster_reorder=np.zeros(raster.shape)\n",
    "    longitud=0\n",
    "    while len(orden_indices)>(max(cluster_index)+1):\n",
    "        orden_indices = orden_indices[:-1]\n",
    "    for i in orden_indices:\n",
    "        raster_reorder[range(longitud,longitud+len(i[0])),:]=raster[i[0],:]\n",
    "        longitud+=len(i[0])\n",
    "    \n",
    "    cmap = matplotlib.cm.get_cmap(name_colormap)    \n",
    "    plt.figure(figsize=(12,6))\n",
    "\n",
    "    ax=plt.axes((0.05,0.35,0.75,0.6)) \n",
    "    for i in range(N):\n",
    "        indices=np.where(raster_reorder[i,:]==1)[0]\n",
    "        plt.plot(indices,raster_reorder[i,indices]*(i+1),\n",
    "                marker='|',linestyle='None',\n",
    "                markersize=markersize,color='black',alpha=0.1)\n",
    "\n",
    "    indices_coactividad_sig=np.where(np.sum(raster_reorder,axis=0)>=umbral)[0]\n",
    "    for ci in range(max(cluster_index)+1):\n",
    "        raster_vec_col_cluster=np.zeros(raster_reorder.shape)\n",
    "        vec_col_cluster=np.where(cluster_index==ci)[0]\n",
    "        raster_vec_col_cluster[:,indices_coactividad_sig[vec_col_cluster]]=raster_reorder[:,indices_coactividad_sig[vec_col_cluster]]\n",
    "        for i in range(N):\n",
    "            indices=np.where(raster_vec_col_cluster[i,:]==1)[0]\n",
    "            plt.plot(indices,raster_vec_col_cluster[i,indices]*(i+1),\n",
    "                    marker='s',linestyle='None',\n",
    "                    markersize=markersize,color=cmap(ci))\n",
    "\n",
    "    ax.set_xlim(0,F-1)\n",
    "    ax.set_ylim(1,N)\n",
    "    plt.xticks([])\n",
    "    plt.ylabel(\"Etiqueta de Neurona\")\n",
    "\n",
    "    ax=plt.axes(((0.05,0.12,0.75,0.2)))\n",
    "    coactividad=np.sum(raster_reorder,axis=0)\n",
    "    coactividad_smooth=smooth(coactividad,3)\n",
    "    fpm=fps*60\n",
    "    tiempo=np.arange(0,F)/fpm\n",
    "    if umbral!=None:\n",
    "        plt.plot([np.min(tiempo),np.max(tiempo)],[umbral,umbral],linestyle='--',color='black',linewidth=1)\n",
    "    xvals = np.linspace(min(tiempo), max(tiempo), len(tiempo)*10)\n",
    "    yinterp = np.interp(xvals, tiempo, coactividad)\n",
    "    y_masked = np.ma.masked_where(yinterp < (umbral-0.5), yinterp)\n",
    "    indices_coactividad_sig=np.where(coactividad>=umbral)[0]\n",
    "    if smoothing==False:\n",
    "        plt.plot(tiempo,coactividad,linewidth=0.5,color='black')\n",
    "        for ci in range(max(cluster_index)+1):\n",
    "            vec_col_cluster=np.where(cluster_index==ci)[0]\n",
    "            y_masked_ci=y_masked.copy()\n",
    "            y_masked_ci.mask=True\n",
    "            for val in vec_col_cluster:\n",
    "                tiempo_mas_cercano=tiempo[indices_coactividad_sig[val]]\n",
    "                indice_pico=np.where(xvals==find_nearest(xvals, tiempo_mas_cercano))[0]\n",
    "                y_masked_ci.mask[range(int(indice_pico)-5,int(indice_pico)+5)]=False\n",
    "            plt.plot(xvals,y_masked_ci,linewidth=4,color=cmap(ci))\n",
    "            #plt.plot(tiempo[indices_coactividad_sig[vec_col_cluster]],\n",
    "            #         coactividad[indices_coactividad_sig[vec_col_cluster]],\n",
    "            #         linestyle='None',marker='o',color=cmap(ci))\n",
    "    else:\n",
    "        plt.plot(tiempo,coactividad_smooth,linewidth=0.5,color='black')\n",
    "    ax.set_xlim(np.min(tiempo),np.max(tiempo))\n",
    "    ax.set_ylim(0,np.max(coactividad)+1)\n",
    "    plt.xlabel(\"Tiempo (min)\")\n",
    "    plt.ylabel(\"Coactividad\")\n",
    "\n",
    "    ax=plt.axes((0.85,0.35,0.1,0.6))\n",
    "    actividad=np.sum(raster_reorder,axis=1)\n",
    "    plt.plot(actividad,np.arange(1,N+1),color='black',linewidth=1)\n",
    "    ax.set_xlim(0,max(actividad)+1)\n",
    "    ax.set_ylim(1,N)\n",
    "    plt.xlabel(\"Cuadros activos\")\n",
    "    plt.yticks([])\n",
    "    \n",
    "    orden_plot=[]\n",
    "    for ar in orden_indices:\n",
    "        for vec in ar:\n",
    "            for val in vec:\n",
    "                orden_plot.append(val) \n",
    "    \n",
    "    return orden_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nuevo_cluster_index(cluster_index,nuevo_orden):\n",
    "    try:\n",
    "        n=len(nuevo_orden)\n",
    "        newCluster_index=np.zeros((len(cluster_index),))\n",
    "        for i in range(max(cluster_index)+1):\n",
    "            indices=np.where(cluster_index==nuevo_orden[i])[0]\n",
    "            newCluster_index[indices]=int(i)\n",
    "        return newCluster_index.astype(int)\n",
    "    except ValueError:\n",
    "        print(ValueError)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_raster_h(raster,fps,cluster_index,name_colormap,smoothing=False,markersize=5,tam_pico_sig=[]):\n",
    "    cmap = matplotlib.cm.get_cmap(name_colormap)\n",
    "    N,F=raster.shape\n",
    "    actividad=np.zeros((N,1))\n",
    "    orden_plot=[]\n",
    "    if len(tam_pico_sig)==0:\n",
    "        plt.figure(figsize=(12,6))\n",
    "\n",
    "        ax=plt.axes((0.05,0.35,0.75,0.6))\n",
    "        count=0\n",
    "        for ci in range(max(cluster_index)+1):\n",
    "            indices_ci=np.where(cluster_index==ci)[0]\n",
    "            for i in indices_ci:\n",
    "                orden_plot.append(i)\n",
    "                indices=np.where(raster[i,:]==1)[0]\n",
    "                if type(cmap)==matplotlib.colors.LinearSegmentedColormap:\n",
    "                    plt.plot(indices,raster[i,indices]*(count+1),\n",
    "                            marker='|',linestyle='None',\n",
    "                            markersize=markersize,color=cmap(ci/max(cluster_index)))\n",
    "                else:\n",
    "                    plt.plot(indices,raster[i,indices]*(count+1),\n",
    "                            marker='|',linestyle='None',\n",
    "                            markersize=markersize,color=cmap(ci))\n",
    "                actividad[count]=np.sum(raster[i,:])*100/F\n",
    "                count+=1\n",
    "        ax.set_xlim(0,F-1)\n",
    "        ax.set_ylim(1,N)\n",
    "        plt.xticks([])\n",
    "        plt.ylabel(\"Etiqueta de Neurona\")\n",
    "\n",
    "        ax=plt.axes(((0.05,0.12,0.75,0.2)))\n",
    "        coactividad=np.sum(raster,axis=0)\n",
    "        fpm=fps*60\n",
    "        tiempo=np.arange(0,F)/fpm\n",
    "\n",
    "        coactividad_clusters=np.zeros((max(cluster_index),len(tiempo)))\n",
    "        for ci in range(max(cluster_index)):\n",
    "            coactividad_clusters[ci,:]=np.sum(raster[np.where(cluster_index==ci)[0],:],axis=0)\n",
    "\n",
    "        if smoothing==False:\n",
    "            for ci in range(max(cluster_index)):\n",
    "                plt.plot(tiempo,coactividad_clusters[ci,:],linewidth=0.5,color=cmap(ci))\n",
    "            plt.plot(tiempo,coactividad,linewidth=0.5,color='black')\n",
    "        else:\n",
    "            for ci in range(max(cluster_index)):\n",
    "                plt.plot(tiempo,smooth(coactividad_clusters[ci,:],3),linewidth=0.5,color=cmap(ci))\n",
    "            coactividad_smooth=smooth(coactividad,3)\n",
    "            plt.plot(tiempo,coactividad_smooth,linewidth=0.5,color='black')\n",
    "        ax.set_xlim(np.min(tiempo),np.max(tiempo))\n",
    "        ax.set_ylim(0,np.max(coactividad)+1)\n",
    "        plt.xlabel(\"Tiempo (min)\")\n",
    "        plt.ylabel(\"Coactividad\")\n",
    "\n",
    "        ax=plt.axes((0.85,0.35,0.1,0.6))\n",
    "        plt.plot(actividad,np.arange(1,N+1),color='black',linewidth=1)\n",
    "        ax.set_xlim(0,max(actividad)+1)\n",
    "        ax.set_ylim(1,N)\n",
    "        plt.xlabel(\"Cuadros activos\")\n",
    "        plt.yticks([])\n",
    "    \n",
    "    elif len(tam_pico_sig)==max(cluster_index)+1:\n",
    "        print(\"dentro\")\n",
    "        plt.figure(figsize=(12,6))\n",
    "\n",
    "        ax=plt.axes((0.05,0.35,0.75,0.6))\n",
    "        count=0\n",
    "        for ci in range(max(cluster_index)+1):\n",
    "            indices_ci=np.where(cluster_index==ci)[0]\n",
    "            coactividad_cluster=np.sum(raster[np.where(cluster_index==ci)[0],:],axis=0)\n",
    "            idx=np.where(coactividad_cluster>=tam_pico_sig[ci])[0]\n",
    "            for i in indices_ci:\n",
    "                orden_plot.append(i)\n",
    "                indices=np.where(raster[i,:]==1)[0]\n",
    "                plt.plot(indices,raster[i,indices]*(count+1),\n",
    "                        marker='|',linestyle='None',\n",
    "                        markersize=markersize,color=cmap(ci),alpha=0.1)\n",
    "                plt.plot(idx,raster[i,idx]*(count+1),\n",
    "                        marker='s',linestyle='None',\n",
    "                        markersize=markersize,color=cmap(ci),alpha=1)\n",
    "                actividad[count]=np.sum(raster[i,:])*100/F\n",
    "                count+=1      \n",
    "        ax.set_xlim(0,F-1)\n",
    "        ax.set_ylim(1,N)\n",
    "        plt.xticks([])\n",
    "        plt.ylabel(\"Etiqueta de Neurona\")\n",
    "\n",
    "        ax=plt.axes(((0.05,0.12,0.75,0.2)))\n",
    "        coactividad=np.sum(raster,axis=0)\n",
    "        fpm=fps*60\n",
    "        tiempo=np.arange(0,F)/fpm\n",
    "\n",
    "        coactividad_clusters=np.zeros((max(cluster_index),len(tiempo)))\n",
    "        for ci in range(max(cluster_index)):\n",
    "            coactividad_clusters[ci,:]=np.sum(raster[np.where(cluster_index==ci)[0],:],axis=0)\n",
    "\n",
    "        if smoothing==False:\n",
    "            for ci in range(max(cluster_index)):\n",
    "                plt.plot(tiempo,coactividad_clusters[ci,:],linewidth=0.5,color=cmap(ci))\n",
    "            plt.plot(tiempo,coactividad,linewidth=0.5,color='black')\n",
    "        else:\n",
    "            for ci in range(max(cluster_index)):\n",
    "                plt.plot(tiempo,smooth(coactividad_clusters[ci,:],3),linewidth=0.5,color=cmap(ci))\n",
    "            coactividad_smooth=smooth(coactividad,3)\n",
    "            plt.plot(tiempo,coactividad_smooth,linewidth=0.5,color='black')\n",
    "        ax.set_xlim(np.min(tiempo),np.max(tiempo))\n",
    "        ax.set_ylim(0,np.max(coactividad)+1)\n",
    "        plt.xlabel(\"Tiempo (min)\")\n",
    "        plt.ylabel(\"Coactividad\")\n",
    "\n",
    "        ax=plt.axes((0.85,0.35,0.1,0.6))\n",
    "        plt.plot(actividad,np.arange(1,N+1),color='black',linewidth=1)\n",
    "        ax.set_xlim(0,max(actividad)+1)\n",
    "        ax.set_ylim(1,N)\n",
    "        plt.xlabel(\"Cuadros activos\")\n",
    "        plt.yticks([])\n",
    "    else:\n",
    "        print(\"El tamaño del vector de picos significativos no coincide con el número de grupos\")\n",
    "    return orden_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_componente_gigante(grafo):\n",
    "    comps=buscar_componentes(grafo)\n",
    "    comp_g=comps[0]\n",
    "    mayor_valor=len(comps[0])\n",
    "    for comp in comps:\n",
    "        if len(comp)>mayor_valor:\n",
    "            comp_g=comp\n",
    "            mayor_valor=len(comp)\n",
    "    nodos_cg=np.sort(np.asarray(comp_g))\n",
    "    return grafo[nodos_cg[:,np.newaxis],nodos_cg]\n",
    "\n",
    "def buscar_componentes(grafo):\n",
    "    N=len(grafo)\n",
    "    visitados=[]\n",
    "    componentes=[]\n",
    "    for i in range(N):\n",
    "        visitados.append(False)\n",
    "    for i in range(N):\n",
    "        if visitados[i]==False:\n",
    "            componente=[]\n",
    "            componentes.append(buscar_en_vecinos(componente,i,visitados,grafo))\n",
    "    return componentes\n",
    "\n",
    "def buscar_en_vecinos(componente,i,visitados,grafo):\n",
    "    visitados[i]=True\n",
    "    componente.append(i)\n",
    "    vecinos=np.where(grafo[i,:]>0)[0]\n",
    "    for j in vecinos:\n",
    "        if visitados[j]==False:\n",
    "            componente=buscar_en_vecinos(componente,j,visitados,grafo)\n",
    "    return componente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_multiple_element(list_object, indices):\n",
    "  indices = sorted(indices, reverse=True)\n",
    "  for idx in indices:\n",
    "        if idx < len(list_object):\n",
    "            list_object.pop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grafo_coactividad(raster,n_sim,p):\n",
    "  N,F=raster.shape\n",
    "  grafo_ponderado=np.zeros((N,N))\n",
    "  grafo_binario=np.zeros((N,N))\n",
    "\n",
    "  mat_conteo=np.zeros((N,N))\n",
    "\n",
    "  mat_coact_real=np.zeros((N,N))\n",
    "  mat_coact_sub=np.zeros((N,N,n_sim))\n",
    "    \n",
    "  for i in range(F):\n",
    "    neuronas_coactivas=np.where(raster[:,i]==1)[0]\n",
    "    for j in neuronas_coactivas:\n",
    "      for k in neuronas_coactivas:\n",
    "        mat_coact_real[j,k]=mat_coact_real[j,k]+1\n",
    "  for i in range(N):\n",
    "    mat_coact_real[i,i]=0\n",
    "\n",
    "  for n in range(n_sim):\n",
    "    raster_sub=raster_subrogado(raster,1)\n",
    "    mat_coact_sub=np.zeros((N,N))\n",
    "    for i in range(F):\n",
    "      neuronas_coactivas=np.where(raster_sub[:,i]==1)[0]\n",
    "      for j in neuronas_coactivas:\n",
    "        for k in neuronas_coactivas:\n",
    "          mat_coact_sub[j,k,n]=mat_coact_sub[j,k,n]+1\n",
    "    for i in range(N):\n",
    "      for j in range(N):\n",
    "        if mat_coact_real[i,j]>mat_coact_sub[i,j,n]:\n",
    "          mat_conteo[i,j]=mat_conteo[i,j]+1\n",
    "  umbral=1-p\n",
    "  for i in range(N):\n",
    "    for j in range(N):\n",
    "      if mat_conteo[i,j]>(n_sim*umbral):\n",
    "        grafo_ponderado[i,j]=mat_coact_real[i,j]\n",
    "        grafo_binario[i,j]=1\n",
    "  \n",
    "  return grafo_binario,grafo_ponderado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grafo_correlaciones(raster,n_sim,p):\n",
    "  N,F=raster.shape\n",
    "  grafo_ponderado=np.zeros((N,N))\n",
    "  grafo_binario=np.zeros((N,N))\n",
    "\n",
    "  mat_conteo=np.zeros((N,N))\n",
    "\n",
    "  mat_corr_real=np.corrcoef(raster)\n",
    "  mat_corr_real[np.where(mat_corr_real<0)]=0\n",
    "    \n",
    "  mat_corr_sub_total=np.zeros((N,N,n_sim))\n",
    "\n",
    "  for n in range(n_sim):\n",
    "    raster_sub=raster_subrogado(raster,1)\n",
    "    mat_corr_sub=np.corrcoef(raster_sub)\n",
    "    #mat_corr_sub[np.where(mat_corr_sub<0)]=0\n",
    "    np.fill_diagonal(mat_corr_sub, 0)\n",
    "    mat_corr_sub_total[:,:,n]=mat_corr_sub\n",
    "    a,b=np.where(mat_corr_real>mat_corr_sub)\n",
    "    mat_conteo[a,b]=mat_conteo[a,b]+1\n",
    "\n",
    "  np.fill_diagonal(mat_corr_real, 0)\n",
    "  umbral=1-p\n",
    "  grafo_binario[np.where(mat_conteo>(n_sim*umbral))]=1\n",
    "  grafo_ponderado=np.corrcoef(raster)\n",
    "  #grafo_ponderado[np.where(mat_conteo<=(n_sim*umbral))]=0\n",
    "  \n",
    "  return grafo_binario,grafo_ponderado,mat_corr_sub_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_experimento(nombre_archivo):\n",
    "  datos=pd.read_csv(nombre_archivo,sep=',',skiprows=4,header=None)\n",
    "  return datos.values.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportar_json(datos,nombre_archivo):\n",
    "  nombre_archivo=os.path.splitext(nombre_archivo)[0]+'.json'\n",
    "  with open(nombre_archivo, \"w\") as outfile: \n",
    "    json.dump(datos, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_coactividad_significativa(raster_real,n_iter,p,graficar=True):\n",
    "    coactividad_real=np.sum(raster_real,axis=0)\n",
    "    frecuencia_coactividad=collections.Counter(coactividad_real)\n",
    "    lista_coactividad_subrogada=[]\n",
    "    lista_hist_subrogada=[]\n",
    "    for i in range(n_iter):\n",
    "        raster_sub=raster_subrogado(raster_real,1)\n",
    "        coactividad_subrogada=np.sum(raster_sub,axis=0)\n",
    "        frecuencia_coactividad_subrogada=collections.Counter(coactividad_subrogada.astype(int))\n",
    "        lista_hist_subrogada.append(frecuencia_coactividad_subrogada)\n",
    "    probabilidades_coactividad=[]\n",
    "\n",
    "    # cuentas=np.zeros((len(frecuencia_coactividad),))\n",
    "    # for sim in lista_hist_subrogada:\n",
    "    #     for i in range(len(frecuencia_coactividad)):\n",
    "    #         if frecuencia_coactividad[i]>=sim[i]:\n",
    "    #             cuentas[i]=cuentas[i]+1\n",
    "\n",
    "    tam_picos=np.sort(list(frecuencia_coactividad.keys()))\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(tam_picos,1-cuentas/n_iter,marker='o')\n",
    "#     plt.plot([min(tam_picos),max(tam_picos)],[p,p],color='red',linestyle=':')\n",
    "#     plt.ylabel('p')\n",
    "#     plt.xlabel('Neuronas activas en un frame')\n",
    "#     plt.title('Montecarlo 1')\n",
    "#     plt.show()\n",
    "\n",
    "    cuentas2=np.zeros((len(frecuencia_coactividad),))\n",
    "    for sim in lista_hist_subrogada:\n",
    "        for i in range(len(frecuencia_coactividad)):\n",
    "            suma_real=0\n",
    "            suma_subr=0\n",
    "            for j in range(i,len(frecuencia_coactividad)):\n",
    "                suma_real+=frecuencia_coactividad[j]\n",
    "            for j in range(i,len(sim)):\n",
    "                suma_subr+=sim[j]\n",
    "            if suma_subr>suma_real:\n",
    "                cuentas2[i]=cuentas2[i]+1\n",
    "    \n",
    "    if graficar:\n",
    "        plt.figure()\n",
    "        plt.plot(tam_picos,cuentas2/n_iter,marker='o')\n",
    "        plt.plot([min(tam_picos),max(tam_picos)],[p,p],color='red',linestyle=':')\n",
    "        plt.ylabel('p')\n",
    "        plt.xlabel('Neuronas activas en un frame')\n",
    "        plt.title('Método de Montecarlo')\n",
    "        plt.show()\n",
    "    \n",
    "    return [tam_picos,cuentas2/n_iter,lista_hist_subrogada]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_subrogado(raster_real,selector):\n",
    "  N,F=raster_real.shape\n",
    "  raster_artificial=np.zeros((N,F))\n",
    "  if selector == 1: #Mantiene número de neuronas y tiempo\n",
    "    for i in range(N):\n",
    "      raster_artificial[i,:]=raster_real[i,np.random.permutation(F)]\n",
    "  elif selector == 2: #Mantiene ISI y tiempo\n",
    "    for i in range(N):\n",
    "      isi=np.diff(np.where(np.concatenate(([1],raster_real[i,:],[1]))==1)).flatten()\n",
    "      t_inicio=isi[0]\n",
    "      t_final=isi[-1]\n",
    "      isi=np.delete(isi,[0])\n",
    "      isi=np.delete(isi,len(isi)-1)\n",
    "      isi_permutado=isi[np.random.permutation(len(isi))]\n",
    "      t_prim_esp=np.random.randint(t_inicio+t_final)\n",
    "      t_activo=np.concatenate(([0],np.cumsum(isi_permutado)))\n",
    "      t_esp=t_activo+t_prim_esp-1\n",
    "      raster_artificial[i,t_esp]=1\n",
    "  return raster_artificial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actividad_acumulada(raster,fps,Normalizar=False):\n",
    "  _,F=raster.shape\n",
    "  fpm=fps*60\n",
    "  tiempo=np.arange(0,F)/fpm\n",
    "  if Normalizar:\n",
    "    texto=\"Actividad Acumulada Normalizada\"\n",
    "    actividad_acumulada=np.cumsum(np.sum(raster,axis=0))/np.sum(np.sum(raster,axis=0))\n",
    "  else:\n",
    "    texto=\"Actividad Acumulada\"\n",
    "    actividad_acumulada=np.cumsum(np.sum(raster,axis=0))\n",
    "  m,b = np.polyfit(tiempo,actividad_acumulada, 1)\n",
    "  y=m*tiempo+b\n",
    "  plt.plot(tiempo,actividad_acumulada)\n",
    "  plt.plot(tiempo,y,'--')\n",
    "  plt.xlim(np.min(tiempo),np.max(tiempo))\n",
    "  plt.ylim(0,max(actividad_acumulada))\n",
    "  plt.xlabel(\"Tiempo (min)\")\n",
    "  plt.ylabel(texto)\n",
    "  return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raster(raster,fps,smoothing=False,umbral=None,markersize=5):\n",
    "    N,F=raster.shape\n",
    "    plt.figure(figsize=(12,6))\n",
    "\n",
    "    ax=plt.axes((0.05,0.35,0.75,0.6)) \n",
    "    for i in range(N):\n",
    "        indices=np.where(raster[i,:]==1)[0]\n",
    "        plt.plot(indices,raster[i,indices]*(i+1),\n",
    "                marker='|',linestyle='None',\n",
    "                markersize=markersize,color='black')\n",
    "    ax.set_xlim(0,F-1)\n",
    "    ax.set_ylim(1,N)\n",
    "    plt.xticks([])\n",
    "    plt.ylabel(\"Etiqueta de Neurona\")\n",
    "\n",
    "    ax=plt.axes(((0.05,0.12,0.75,0.2)))\n",
    "    coactividad=np.sum(raster,axis=0)\n",
    "    coactividad_smooth=smooth(coactividad,3)\n",
    "    fpm=fps*60\n",
    "    tiempo=np.arange(0,F)/fpm\n",
    "    if smoothing==False:\n",
    "        plt.plot(tiempo,coactividad,linewidth=0.5,color='black')\n",
    "    else:\n",
    "        plt.plot(tiempo,coactividad_smooth,linewidth=0.5,color='black')\n",
    "    if umbral!=None:\n",
    "        plt.plot([np.min(tiempo),np.max(tiempo)],[umbral-0.2,umbral-0.2],linestyle='--',color='black',linewidth=1)\n",
    "    ax.set_xlim(np.min(tiempo),np.max(tiempo))\n",
    "    ax.set_ylim(0,np.max(coactividad)+1)\n",
    "    plt.xlabel(\"Tiempo (min)\")\n",
    "    plt.ylabel(\"Coactividad\")\n",
    "\n",
    "    ax=plt.axes((0.85,0.35,0.1,0.6))\n",
    "    actividad=np.sum(raster,axis=1)\n",
    "    plt.plot(actividad,np.arange(1,N+1),color='black',linewidth=1)\n",
    "    ax.set_xlim(0,max(actividad)+1)\n",
    "    ax.set_ylim(1,N)\n",
    "    plt.xlabel(\"Cuadros activos\")\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raster_coactividad_significativa(raster,fps,umbral_coactividad):\n",
    "  N,F=raster.shape\n",
    "  plt.figure(figsize=(12,6))\n",
    "\n",
    "  f_coac_sig=np.where(np.sum(raster,axis=0)>=umbral_coactividad)[0]\n",
    "  raster_atras=raster.copy()\n",
    "  raster_atras[:,f_coac_sig]=0\n",
    "  f_no_coac_sig=np.where(np.sum(raster,axis=0)<umbral_coactividad)[0]\n",
    "  raster_adelante=raster.copy()\n",
    "  raster_adelante[:,f_no_coac_sig]=0\n",
    "\n",
    "  ax=plt.axes((0.05,0.35,0.75,0.6)) \n",
    "  for i in range(N):\n",
    "    indices=np.where(raster_atras[i,:]==1)[0]\n",
    "    plt.plot(indices,raster_atras[i,indices]*(i+1),\n",
    "            marker='|',linestyle='None',\n",
    "            markersize=1,color='black')\n",
    "    indices=np.where(raster_adelante[i,:]==1)[0]\n",
    "    plt.plot(indices,raster_adelante[i,indices]*(i+1),\n",
    "            marker='o',linestyle='None',\n",
    "            markersize=2,color='red')\n",
    "  ax.set_xlim(0,F-1)\n",
    "  ax.set_ylim(1,N)\n",
    "  plt.xticks([])\n",
    "  plt.ylabel(\"Etiqueta de Neurona\")\n",
    "\n",
    "  ax=plt.axes(((0.05,0.12,0.75,0.2)))\n",
    "  y=np.sum(raster,axis=0)\n",
    "  fpm=fps*60\n",
    "  x=np.arange(0,F)/fpm\n",
    "  xvals = np.linspace(min(x), max(x), len(x)*10)\n",
    "  yinterp = np.interp(xvals, x, y)\n",
    "  y_masked = np.ma.masked_where(yinterp < (umbral_coactividad-0.5), yinterp)\n",
    "  plt.plot(xvals,yinterp,linewidth=0.5,color='black')\n",
    "  plt.plot(xvals,y_masked,linewidth=2,color='red')\n",
    "  ax.set_xlim(np.min(tiempo),np.max(tiempo))\n",
    "  ax.set_ylim(0,np.max(y)+1)\n",
    "  plt.xlabel(\"Tiempo (min)\")\n",
    "  plt.ylabel(\"Coactividad\")\n",
    "\n",
    "  ax=plt.axes((0.85,0.35,0.1,0.6))\n",
    "  actividad=np.sum(raster,axis=1)\n",
    "  base=plt.gca().transData\n",
    "  rot=tfs.Affine2D().rotate_deg(270)\n",
    "  plt.plot(np.flip(actividad),color='black',\n",
    "          linewidth=1,transform=rot+base)\n",
    "  plt.xlabel(\"Cuadros activos\")\n",
    "  plt.yticks([])\n",
    "  ax.set_xlim(0,np.max(actividad)+1)\n",
    "  ax.set_ylim(-N+1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teachers_round(x):\n",
    "    '''\n",
    "    Do rounding such that .5 always rounds to 1, and not bankers rounding.\n",
    "    This is for compatibility with matlab functions, and ease of testing.\n",
    "    '''\n",
    "    if ((x > 0) and (x % 1 >= 0.5)) or ((x < 0) and (x % 1 > 0.5)):\n",
    "        return int(np.ceil(x))\n",
    "    else:\n",
    "        return int(np.floor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_proportional(W, p, copy=True):\n",
    "    '''\n",
    "    This function \"thresholds\" the connectivity matrix by preserving a\n",
    "    proportion p (0<p<1) of the strongest weights. All other weights, and\n",
    "    all weights on the main diagonal (self-self connections) are set to 0.\n",
    "    If copy is not set, this function will *modify W in place.*\n",
    "    Parameters\n",
    "    ----------\n",
    "    W : np.ndarray\n",
    "        weighted connectivity matrix\n",
    "    p : float\n",
    "        proportional weight threshold (0<p<1)\n",
    "    copy : bool\n",
    "        if True, returns a copy of the matrix. Otherwise, modifies the matrix\n",
    "        in place. Default value=True.\n",
    "    Returns\n",
    "    -------\n",
    "    W : np.ndarray\n",
    "        thresholded connectivity matrix\n",
    "    Notes\n",
    "    -----\n",
    "    The proportion of elements set to 0 is a fraction of all elements\n",
    "    in the matrix, whether or not they are already 0. That is, this function\n",
    "    has the following behavior:\n",
    "    >> x = np.random.random_sample((10,10))\n",
    "    >> x_25 = threshold_proportional(x, .25)\n",
    "    >> np.size(np.where(x_25)) #note this double counts each nonzero element\n",
    "    46\n",
    "    >> x_125 = threshold_proportional(x, .125)\n",
    "    >> np.size(np.where(x_125))\n",
    "    22\n",
    "    >> x_test = threshold_proportional(x_25, .5)\n",
    "    >> np.size(np.where(x_test))\n",
    "    46\n",
    "    That is, the 50% thresholding of x_25 does nothing because >=50% of the\n",
    "    elements in x_25 are aleady <=0. This behavior is the same as in BCT. Be\n",
    "    careful with matrices that are both signed and sparse.\n",
    "    '''\n",
    "    if copy:\n",
    "        W = W.copy()\n",
    "    n = len(W) # number of nodes\n",
    "    np.fill_diagonal(W, 0) # clear diagonal\n",
    "\n",
    "    if np.allclose(W, W.T): # if symmetric matrix\n",
    "        W[np.tril_indices(n)] = 0 # ensure symmetry is preserved\n",
    "        ud = 2 # halve number of removed links\n",
    "    else:\n",
    "        ud = 1\n",
    "\n",
    "    ind = np.where(W) # find all links\n",
    "\n",
    "    I = np.argsort(W[ind])[::-1] # sort indices by magnitude\n",
    "\n",
    "    en = int(teachers_round((n * n - n) * p / ud)) # number of links to be preserved\n",
    "\n",
    "    W[(ind[0][I][en:], ind[1][I][en:])] = 0  # apply threshold\n",
    "    #W[np.ix_(ind[0][I][en:], ind[1][I][en:])]=0\n",
    "\n",
    "    if ud == 2: # if symmetric matrix\n",
    "        W[:, :] = W + W.T # reconstruct symmetry\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def community_louvain(W, gamma=1, ci=None, B='modularity', seed=None):\n",
    "    '''\n",
    "    The optimal community structure is a subdivision of the network into\n",
    "    nonoverlapping groups of nodes which maximizes the number of within-group\n",
    "    edges and minimizes the number of between-group edges.\n",
    "    This function is a fast an accurate multi-iterative generalization of the\n",
    "    louvain community detection algorithm. This function subsumes and improves\n",
    "    upon modularity_[louvain,finetune]_[und,dir]() and additionally allows to\n",
    "    optimize other objective functions (includes built-in Potts Model i\n",
    "    Hamiltonian, allows for custom objective-function matrices).\n",
    "    Parameters\n",
    "    ----------\n",
    "    W : NxN np.array\n",
    "        directed/undirected weighted/binary adjacency matrix\n",
    "    gamma : float\n",
    "        resolution parameter. default value=1. Values 0 <= gamma < 1 detect\n",
    "        larger modules while gamma > 1 detects smaller modules.\n",
    "        ignored if an objective function matrix is specified.\n",
    "    ci : Nx1 np.arraylike\n",
    "        initial community affiliation vector. default value=None\n",
    "    B : str | NxN np.arraylike\n",
    "        string describing objective function type, or provides a custom\n",
    "        NxN objective-function matrix. builtin values \n",
    "            'modularity' uses Q-metric as objective function\n",
    "            'potts' uses Potts model Hamiltonian.\n",
    "            'negative_sym' symmetric treatment of negative weights\n",
    "            'negative_asym' asymmetric treatment of negative weights\n",
    "    seed : hashable, optional\n",
    "        If None (default), use the np.random's global random state to generate random numbers.\n",
    "        Otherwise, use a new np.random.RandomState instance seeded with the given value.\n",
    "    Returns\n",
    "    -------\n",
    "    ci : Nx1 np.array\n",
    "        final community structure\n",
    "    q : float\n",
    "        optimized q-statistic (modularity only)\n",
    "    '''\n",
    "    rng = get_rng(seed)\n",
    "    n = len(W)\n",
    "    s = np.sum(W)\n",
    "\n",
    "    #if np.min(W) < -1e-10:\n",
    "    #    raise BCTParamError('adjmat must not contain negative weights')\n",
    "\n",
    "    if ci is None:\n",
    "        ci = np.arange(n) + 1\n",
    "    else:\n",
    "        if len(ci) != n:\n",
    "            raise BCTParamError('initial ci vector size must equal N')\n",
    "        _, ci = np.unique(ci, return_inverse=True)\n",
    "        ci += 1\n",
    "    Mb = ci.copy()\n",
    "    renormalize = False\n",
    "    if B in ('negative_sym', 'negative_asym'):\n",
    "        renormalize = True\n",
    "        W0 = W * (W > 0)\n",
    "        s0 = np.sum(W0)\n",
    "        B0 = W0 - gamma * np.outer(np.sum(W0, axis=1), np.sum(W0, axis=0)) / s0\n",
    "\n",
    "        W1 = -W * (W < 0)\n",
    "        s1 = np.sum(W1)\n",
    "        if s1:\n",
    "            B1 = W1 - gamma * np.outer(np.sum(W1, axis=1), np.sum(W1, axis=0)) / s1\n",
    "        else:\n",
    "            B1 = 0\n",
    "\n",
    "    elif np.min(W) < -1e-10:\n",
    "        raise BCTParamError(\"Input connection matrix contains negative \"\n",
    "            'weights but objective function dealing with negative weights '\n",
    "            'was not selected')\n",
    "\n",
    "    if B == 'potts' and np.any(np.logical_not(np.logical_or(W == 0, W == 1))):\n",
    "        raise BCTParamError('Potts hamiltonian requires binary input matrix')\n",
    "\n",
    "    if B == 'modularity':\n",
    "        B = W - gamma * np.outer(np.sum(W, axis=1), np.sum(W, axis=0)) / s\n",
    "    elif B == 'potts':\n",
    "        B = W - gamma * np.logical_not(W)\n",
    "    elif B == 'negative_sym':\n",
    "        B = (B0 / (s0 + s1)) - (B1 / (s0 + s1))\n",
    "    elif B == 'negative_asym':\n",
    "        B = (B0 / s0) - (B1 / (s0 + s1))\n",
    "    else:\n",
    "        try:\n",
    "            B = np.array(B)\n",
    "        except:\n",
    "            raise BCTParamError('unknown objective function type')\n",
    "\n",
    "        if B.shape != W.shape:\n",
    "            raise BCTParamError('objective function matrix does not match '\n",
    "                                'size of adjacency matrix')\n",
    "        if not np.allclose(B, B.T):\n",
    "            print ('Warning: objective function matrix not symmetric, '\n",
    "                   'symmetrizing')\n",
    "            B = (B + B.T) / 2\n",
    "    \n",
    "    Hnm = np.zeros((n, n))\n",
    "    for m in range(1, n + 1):\n",
    "        Hnm[:, m - 1] = np.sum(B[:, ci == m], axis=1)  # node to module degree\n",
    "    H = np.sum(Hnm, axis=1)  # node degree\n",
    "    Hm = np.sum(Hnm, axis=0)  # module degree\n",
    "\n",
    "    q0 = -np.inf\n",
    "    # compute modularity\n",
    "    q = np.sum(B[np.tile(ci, (n, 1)) == np.tile(ci, (n, 1)).T]) / s\n",
    "\n",
    "    first_iteration = True\n",
    "\n",
    "    while q - q0 > 1e-10:\n",
    "        it = 0\n",
    "        flag = True\n",
    "        while flag:\n",
    "            it += 1\n",
    "            if it > 1000:\n",
    "                raise BCTParamError('Modularity infinite loop style G. '\n",
    "                                    'Please contact the developer.')\n",
    "            flag = False\n",
    "            for u in rng.permutation(n):\n",
    "                ma = Mb[u] - 1\n",
    "                dQ = Hnm[u, :] - Hnm[u, ma] + B[u, u]  # algorithm condition\n",
    "                dQ[ma] = 0\n",
    "\n",
    "                max_dq = np.max(dQ)\n",
    "                if max_dq > 1e-10:\n",
    "                    flag = True\n",
    "                    mb = np.argmax(dQ)\n",
    "\n",
    "                    Hnm[:, mb] += B[:, u]\n",
    "                    Hnm[:, ma] -= B[:, u]  # change node-to-module strengths\n",
    "\n",
    "                    Hm[mb] += H[u]\n",
    "                    Hm[ma] -= H[u]  # change module strengths\n",
    "\n",
    "                    Mb[u] = mb + 1\n",
    "\n",
    "        _, Mb = np.unique(Mb, return_inverse=True)\n",
    "        Mb += 1\n",
    "\n",
    "        M0 = ci.copy()\n",
    "        if first_iteration:\n",
    "            ci = Mb.copy()\n",
    "            first_iteration = False\n",
    "        else:\n",
    "            for u in range(1, n + 1):\n",
    "                ci[M0 == u] = Mb[u - 1]  # assign new modules\n",
    "\n",
    "        n = np.max(Mb)\n",
    "        b1 = np.zeros((n, n))\n",
    "        for i in range(1, n + 1):\n",
    "            for j in range(i, n + 1):\n",
    "                # pool weights of nodes in same module\n",
    "                bm = np.sum(B[np.ix_(Mb == i, Mb == j)])\n",
    "                b1[i - 1, j - 1] = bm\n",
    "                b1[j - 1, i - 1] = bm\n",
    "        B = b1.copy()\n",
    "\n",
    "        Mb = np.arange(1, n + 1)\n",
    "        Hnm = B.copy()\n",
    "        H = np.sum(B, axis=0)\n",
    "        Hm = H.copy()\n",
    "\n",
    "        q0 = q\n",
    "\n",
    "        q = np.trace(B)  # compute modularity\n",
    "    \n",
    "    # Workaround to normalize\n",
    "    if not renormalize:\n",
    "        return ci, q/s\n",
    "    else:\n",
    "        return ci, q"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
